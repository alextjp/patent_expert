{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7886bfe6-5fb6-46c3-9ac0-f8514d567097",
   "metadata": {},
   "source": [
    "# Importing OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e24681-87a1-4a90-a27c-b0e46a2ccb4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "!pip install -qU langchain==0.0.354 \\\n",
    "    openai==1.6.1 \\\n",
    "    pinecone-client==3.1.0 \\\n",
    "    tiktoken==0.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf85e57-bb8e-4370-a3fe-8f0c642bc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setting the OpenAI environment variable\n",
    "os.environ[\"OPENAI_APIKEY\"] = \"API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfae8b8-f689-4da6-879d-505eaa7c87ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OPENAI_APIKEY = os.getenv('OPENAI_APIKEY')\n",
    "print(OPENAI_APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c2b45-6fd8-48d1-b0d2-5369192ab2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_APIKEY\"],\n",
    "    model='gpt-3.5-turbo-1106'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefb2a3-3948-47c1-a791-860ee2e141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to know more about how mobile networks are being used in mining operations.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f42e8-df2d-4129-9cee-2199d01d6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5f4d0-972e-4745-abf5-9d27a68698d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f0975-4bd9-4019-a370-437d06c12aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"how are these networks different from regular every day mobile networks in the cities?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aadc9b-93af-42b3-b1dc-d354386582b9",
   "metadata": {},
   "source": [
    "# Importing Relevant Patent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cd88a-148b-4f2d-b7bb-f829990b6b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    dataset = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            dataset.append(json.loads(line))\n",
    "    return dataset\n",
    "\n",
    "# Path to your .jsonl file\n",
    "path_to_jsonl_file = '/Users/alexsar/Downloads/train.jsonl'\n",
    "\n",
    "# Load the data\n",
    "dataset = load_jsonl(path_to_jsonl_file)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "data = pd.DataFrame(dataset)\n",
    "\n",
    "# Example usage: print first few items\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a878324-1a92-47fb-b3c3-e2cc93f7c74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699c386-3f9e-447a-9e3b-516356861c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your loaded dataset as a DataFrame\n",
    "print(data.info())  # Get a concise summary of the DataFrame\n",
    "print(data.head())  # Print the first few entries of the DataFrame to understand what each column contains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a348d-8fff-47b3-8328-b0d4edaa0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading preprocessed data from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a608e4-bd57-412c-a421-f5251e41538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"alsolacol/schlumberger-patents-dataset-chunked\", split='train')\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b83c5-2206-4c6d-9a9e-3ea1efae6fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3201f55-3bd0-4a0b-84f4-29ec0cb8d55c",
   "metadata": {},
   "source": [
    "# Upgesting to Pinecone DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a45802-154f-410f-983b-13ece526affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setting the Pinecone API environment variable\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"PINECONE_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ccc4b1-bd5b-4cd1-834b-69f152c9af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "print(PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6e9a0-dcf9-4b24-a4a7-f85a35682390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\") \n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8056b-1a33-4cdd-999f-e61cc72de264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396d4c0-96be-4292-9018-6f7c2b0dc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'llama-2-rag'\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # dimensionality of ada 002\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4983317-059f-4d30-a8fa-9936678c5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the embeddings model with the API key\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=\"OPENAI_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3c8b4-f56b-434f-a758-b11418f81049",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049cdcb-50ca-43c3-b35a-388ce3bf83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [f\"{x['publication_number']}-{x['filing_date']}\" for i, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['split_preprocessed_combined_text'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['aggregated_representative_docs'],\n",
    "         'inventors': x['inventors'],\n",
    "         'title': x['title']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63a36d-c319-4571-8207-c8a25c02e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3754e45-0166-4e74-90a6-6d8c3d7cc8ab",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309e5bb-78c8-466b-8058-b0c0e9011484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7853cc-6815-4003-9cf9-c99c73afb026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"What is so special about mobile networks in mining operations?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb267f-fdc3-4a08-bf7c-aff46e00d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6add9-e74c-4e8c-b78e-335bc1b1d783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a09e0-5a64-46c4-b1e3-7e43896b3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt without RAG\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64667c4a-f607-4569-99f2-1f95ad43a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"who are some of the inventors who worked on mobile networks in mining?\"\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580ae65-1044-47d7-8e9b-dff44ee95276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding context to the new user prompt with RAG\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(\n",
    "        \"who are some of the inventors who worked on mobile networks in mining based on the data provided below?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5868b6-fcfb-440a-b141-3158b1d03977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226ba98-84d0-4140-a893-e527d4539a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90dc524-578b-4bc3-899c-46ac63c7e9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_venv",
   "language": "python",
   "name": "huggingface_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
